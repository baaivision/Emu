<div align="center">

<h2>Emu: Open Multimodal Generalists from BAAI</h2>


</div>

---


- [**Emu1**](Emu1) (Arxiv 2023) - Generative Pretraining in Multimodality

- [**Emu2**](Emu2) (Arxiv 2023) - Generative Multimodal Models are In-Context Learners

## News
- 2023.7 Inference code and model of Emu1 are available.
- 2023.12 Inference code, model and Demo of Emu2 are available. Enjoy the [Demo](https://huggingface.co/spaces/BAAI/Emu2).

## Hightlights
- State-of-the-art performance
- Next-generation capabilities
- A base model for diverse tasks

## Contact
- **We are hiring** at all levels at BAAI Vision Team, including full-time researchers, engineers and interns. 
If you are interested in working with us on **foundation model, visual perception and multimodal learning**, please contact [Xinlong Wang](https://www.xloong.wang/) (`wangxinlong@baai.ac.cn`).


## Misc

<div align="center">

[![Stargazers repo roster for @baaivision/Emu](https://reporoster.com/stars/baaivision/Emu)](https://github.com/baaivision/Emu/stargazers)


[![Forkers repo roster for @baaivision/Emu](https://reporoster.com/forks/baaivision/Emu)](https://github.com/baaivision/Emu/network/members)


[![Star History Chart](https://api.star-history.com/svg?repos=baaivision/Emu&type=Date)](https://star-history.com/#baaivision/Emu&Date)

</div>
